{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6959beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from itertools import product\n",
    "from skimage.feature import local_binary_pattern, hog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55757c64",
   "metadata": {},
   "source": [
    "previous idea : Basic histograms for each channel, so: H: 180 bins, S: 256 bins, V: 256 bins. this resulted in a feature vector that was too big.\n",
    "\n",
    "current idea: extract the mean and std for each channel (hsv) instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46343e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hsv_stats(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    mean_h, std_h  = np.mean(h), np.std(h)\n",
    "    mean_s, std_s  = np.mean(s), np.std(s)\n",
    "    mean_v, std_v  = np.mean(v), np.std(v)\n",
    "\n",
    "    return np.array([mean_h, std_h, mean_s, std_s, mean_v, std_v])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec2173",
   "metadata": {},
   "source": [
    "Laplacian operator is sensitive to noise so blur the image slightly - I am using a 3x3 kernel to not blur too much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571a8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_laplace_variance(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    return np.array([cv2.Laplacian(gray_blurred, cv2.CV_32F).var()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088d6c7",
   "metadata": {},
   "source": [
    "HOG to extract edge/shape information from images.\n",
    "\n",
    "pixels_per_cell will be tuned by trying combinations for (8, 8), (16, 16) since it is the most effective parameter.\n",
    "\n",
    "for other parameters, use the default values to not make the problem too complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4595509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image, pixels_per_cell):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return hog(gray, orientations=9, pixels_per_cell=pixels_per_cell, cells_per_block=(2, 2), block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee6522",
   "metadata": {},
   "source": [
    "LBP to extract texture from images. ['uniform'](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.local_binary_pattern) used to make result rotation invariant and to have a lower dimensional feature vector.\n",
    "\n",
    "lbp_points and lbp_radius will be tuned by trying combinations for lbp_points = 8, 12 and lbp_radius = 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c097dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_histogram(image, lbp_points, lbp_radius):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=lbp_points, R=lbp_radius, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=lbp_points + 2, range=(0, lbp_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "908ebe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_features_for_image(image, hog_pixels, lbp_points, lbp_radius):\n",
    "    hsv_hist = extract_hsv_stats(image)\n",
    "    laplace_var = extract_laplace_variance(image)\n",
    "    lbp_hist = extract_lbp_histogram(image, lbp_points, lbp_radius)\n",
    "    hog_feats = extract_hog_features(image, hog_pixels)\n",
    "    all_features = np.hstack([hsv_hist, laplace_var, lbp_hist, hog_feats])\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5ee6ac",
   "metadata": {},
   "source": [
    "for each hyperparameter combination, extract features and save in a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e581839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---  dataset1 ---\n",
      "\n",
      "processing dataset1_hog8x8_lbp8p1r\n",
      "\n",
      "completed extracting  for 6862 images in 105.54 seconds\n",
      "\n",
      "processing dataset1_hog8x8_lbp8p2r\n",
      "\n",
      "completed extracting  for 6862 images in 100.38 seconds\n",
      "\n",
      "processing dataset1_hog8x8_lbp12p1r\n",
      "\n",
      "completed extracting  for 6862 images in 107.59 seconds\n",
      "\n",
      "processing dataset1_hog8x8_lbp12p2r\n",
      "\n",
      "completed extracting  for 6862 images in 107.35 seconds\n",
      "\n",
      "processing dataset1_hog16x16_lbp8p1r\n",
      "\n",
      "completed extracting  for 6862 images in 55.32 seconds\n",
      "\n",
      "processing dataset1_hog16x16_lbp8p2r\n",
      "\n",
      "completed extracting  for 6862 images in 55.34 seconds\n",
      "\n",
      "processing dataset1_hog16x16_lbp12p1r\n",
      "\n",
      "completed extracting  for 6862 images in 66.35 seconds\n",
      "\n",
      "processing dataset1_hog16x16_lbp12p2r\n",
      "\n",
      "completed extracting  for 6862 images in 65.01 seconds\n",
      "\n",
      "---  dataset2 ---\n",
      "\n",
      "processing dataset2_hog8x8_lbp8p1r\n",
      "\n",
      "completed extracting  for 3116 images in 44.59 seconds\n",
      "\n",
      "processing dataset2_hog8x8_lbp8p2r\n",
      "\n",
      "completed extracting  for 3116 images in 44.59 seconds\n",
      "\n",
      "processing dataset2_hog8x8_lbp12p1r\n",
      "\n",
      "completed extracting  for 3116 images in 48.99 seconds\n",
      "\n",
      "processing dataset2_hog8x8_lbp12p2r\n",
      "\n",
      "completed extracting  for 3116 images in 48.11 seconds\n",
      "\n",
      "processing dataset2_hog16x16_lbp8p1r\n",
      "\n",
      "completed extracting  for 3116 images in 23.89 seconds\n",
      "\n",
      "processing dataset2_hog16x16_lbp8p2r\n",
      "\n",
      "completed extracting  for 3116 images in 23.96 seconds\n",
      "\n",
      "processing dataset2_hog16x16_lbp12p1r\n",
      "\n",
      "completed extracting  for 3116 images in 28.35 seconds\n",
      "\n",
      "processing dataset2_hog16x16_lbp12p2r\n",
      "\n",
      "completed extracting  for 3116 images in 27.58 seconds\n"
     ]
    }
   ],
   "source": [
    "DATASETS_TO_PROCESS = ['dataset1', 'dataset2']\n",
    "FEATURES_DIR = 'extracted_features'\n",
    "os.makedirs(FEATURES_DIR, exist_ok=True)\n",
    "\n",
    "hog_pixels_options = [(8, 8), (16, 16)]\n",
    "lbp_points_options = [8, 12]\n",
    "lbp_radius_options = [1, 2]\n",
    "all_combinations = list(product(hog_pixels_options, lbp_points_options, lbp_radius_options))\n",
    "\n",
    "\n",
    "for dataset_name in DATASETS_TO_PROCESS:\n",
    "    print(f'\\n---  {dataset_name} ---')\n",
    "    \n",
    "    # load preprocessed data\n",
    "\n",
    "    filepath = os.path.join('preprocessed_data', f'{dataset_name}_processed.npz')\n",
    "    with np.load(filepath, allow_pickle=True) as data:\n",
    "        images, labels, class_map = data['images'], data['labels'], data['class_map'].item()\n",
    "\n",
    "    for hog_pixels, lbp_points, lbp_radius in all_combinations:\n",
    "        \n",
    "        # create file name to save\n",
    "\n",
    "        hog_str = f'hog{hog_pixels[0]}x{hog_pixels[1]}'\n",
    "        lbp_str = f'lbp{lbp_points}p{lbp_radius}r'\n",
    "        feature_set_name = f'{dataset_name}_{hog_str}_{lbp_str}'\n",
    "        output_path = os.path.join(FEATURES_DIR, f'{feature_set_name}.npz')\n",
    "        \n",
    "        print(f'\\nprocessing {feature_set_name}')\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            print('\\nfeatures already extracted for this combination, skipping...')\n",
    "            continue\n",
    "            \n",
    "        start_time = time.time()\n",
    "        \n",
    "        features_list = []\n",
    "        for image in images:\n",
    "            features = extract_all_features_for_image(image, hog_pixels, lbp_points, lbp_radius)\n",
    "            features_list.append(features)\n",
    "        \n",
    "        features_array = np.array(features_list)\n",
    "        \n",
    "        np.savez_compressed(output_path, features=features_array, labels=labels, class_map=class_map)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f'\\ncompleted extracting  for {len(images)} images in {end_time - start_time:.2f} seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
