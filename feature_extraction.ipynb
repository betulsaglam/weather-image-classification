{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55757c64",
   "metadata": {},
   "source": [
    "Basic histograms for each channel, so: H: 180 bins, S: 256 bins, V: 256 bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46343e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hsv_histogram(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h_hist = cv2.calcHist([hsv], [0], None, [180], [0, 180])\n",
    "    s_hist = cv2.calcHist([hsv], [1], None, [256], [0, 256])\n",
    "    v_hist = cv2.calcHist([hsv], [2], None, [256], [0, 256])\n",
    "    cv2.normalize(h_hist, h_hist)\n",
    "    cv2.normalize(s_hist, s_hist)\n",
    "    cv2.normalize(v_hist, v_hist)\n",
    "    return np.concatenate([h_hist, s_hist, v_hist]).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ec2173",
   "metadata": {},
   "source": [
    "Laplacian operator is sensitive to noise so blur the image slightly - I am using a 3x3 kernel to not blur too much\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571a8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_laplace_variance(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    return np.array([cv2.Laplacian(gray_blurred, cv2.CV_64F).var()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a088d6c7",
   "metadata": {},
   "source": [
    "HOG to extract edge/shape information from images.\n",
    "\n",
    "pixels_per_cell will be tuned by trying combinations for (8, 8), (16, 16) since it is the most effective parameter.\n",
    "\n",
    "for other parameters, use the default values to not make the problem too complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4595509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(image, pixels_per_cell):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    return hog(gray, orientations=9, pixels_per_cell=pixels_per_cell, cells_per_block=(3, 3), block_norm='L2-Hys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ee6522",
   "metadata": {},
   "source": [
    "LBP to extract texture from images. ['uniform'](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.local_binary_pattern) used to make result rotation invariant and to have a lower dimensional feature vector.\n",
    "\n",
    "lbp_points and lbp_radius will be tuned by trying combinations for lbp_points = 8, 16 and lbp_radius = 1, 2, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp_histogram(image, lbp_points, lbp_radius):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    lbp = local_binary_pattern(gray, P=lbp_points, R=lbp_radius, method='uniform')\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=lbp_points + 2, range=(0, lbp_points + 2))\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= hist.sum()\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2665c6",
   "metadata": {},
   "source": [
    "Wrap feature extraction in a \"transformer\" class so that we can put it in a pipeline and GridSearchCV can tune hyperparameters for HOG, LBP features at the same time as the machine learning model hyperparameters.\n",
    "\n",
    "[Creating custom transformers in python](https://medium.com/@pgshanding/creating-custom-transformers-in-python-and-scikit-learn-10767487017e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3020eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lbp_radius=1, lbp_points=8, hog_pixels_per_cell=(8, 8)):\n",
    "        self.lbp_radius = lbp_radius\n",
    "        self.lbp_points = lbp_points\n",
    "        self.hog_pixels_per_cell = hog_pixels_per_cell\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self # fit method typically does nothing for transformers\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        features_list = []\n",
    "        total_images = len(X)\n",
    "        print(f'starting feature extraction for {total_images} images...')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, image in enumerate(X):\n",
    "            hsv_hist = extract_hsv_histogram(image)\n",
    "            laplace_var = extract_laplace_variance(image)\n",
    "            lbp_hist = extract_lbp_histogram(image, self.lbp_points, self.lbp_radius)\n",
    "            hog_feats = extract_hog_features(image, self.hog_pixels_per_cell)\n",
    "            \n",
    "            all_features = np.hstack([hsv_hist, laplace_var, lbp_hist, hog_feats])\n",
    "            features_list.append(all_features)\n",
    "        \n",
    "        total = time.time() - start_time\n",
    "        print(f'finished extracting features in {total} seconds')\n",
    "        return np.array(features_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
